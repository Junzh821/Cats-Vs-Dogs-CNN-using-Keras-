{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats Vs Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'test']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2                 \n",
    "import numpy as np         \n",
    "import os                  \n",
    "from random import shuffle\n",
    "from tqdm import tqdm      \n",
    "\n",
    "train_dir = '../input/train'\n",
    "test_dir = '../input/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c80cd80be9d850003f68e59057d5ba9a6d52b43a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label(img):\n",
    "    label = img.split('.')[0]\n",
    "    if label == 'cat': \n",
    "        return [1,0]\n",
    "    elif label == 'dog': \n",
    "        return [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Y and test_y as one hot array.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing and collecting train and test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "f0f1ada45edbc50ee8a715361b535e76dc8731ec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def making_train_data():\n",
    "    training_data = []\n",
    "    \n",
    "    for img in tqdm(os.listdir(train_dir)):\n",
    "        label = get_label(img)\n",
    "        path = os.path.join(train_dir,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (50,50))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "        \n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "e75ed4e473a4291280a90dfcd7e5bfb21457e954",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def making_test_data():\n",
    "    testing_data = []\n",
    "    \n",
    "    for img in tqdm(os.listdir(test_dir)):\n",
    "        path = os.path.join(test_dir , img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path , cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img , (50,50))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "2c3359f6cfe6e81a34e28831a9c6f48e5dbc5588"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:17<00:00, 321.78it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = making_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "b9f6580cdf4598e86c4db3fe262aff82aa7c6120"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "57e5d2067ad790344118caa9c3a480499a1fb513",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train_data[0:20000]\n",
    "test = train_data[20000:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "c77070b911daae6f0be5d8556270966c7f639978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 5000\n"
     ]
    }
   ],
   "source": [
    "print(len(train) , len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "8cf6fd88eb44e07ddc163cbd9bd8b8433619d371",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,1,50,50)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,1,50,50)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ImageDataGenerator to avoid overfitting the model with training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "49511c921e399fd0d7a8c53133d5421ea45a2eb6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False,  \n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.0,  \n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip=False, \n",
    "        vertical_flip=False)  \n",
    "\n",
    "datagen.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using ReduceLROnPlateau to reduce the learning rate after certain epochs with callbacks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "88c97ab677d33df3c5da5c58509688778fd9dbef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/callbacks.py:919: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` insted.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "283a16994d0b7f9d2415faf3c3128a73afd86f1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.asarray(Y)\n",
    "Y.reshape(len(Y) , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "719b0f7eea83f3911e12505913568b302f878cc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = np.asarray(test_y)\n",
    "test_y.reshape(len(test_y) , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "9295d203164fc199cd4784db0d49c175450508a7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = test_x.reshape(-1, 1, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "577c6251872bde2b13b54be8edea2095e1fd0405",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = test_x / 255\n",
    "X = X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "8c6a06cbab7c8fcd7ec4aec37dbe0eb5a9ab2c6f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D , BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_uuid": "da9272b73522ea4388780ba10b622aa11d7ee3f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_59 (Conv2D)           (None, 32, 50, 50)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 32, 50, 50)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 32, 25, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 64, 25, 25)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 64, 25, 25)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 64, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 96, 12, 12)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 96, 10, 10)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 96, 5, 5)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 128, 5, 5)         110720    \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 128, 3, 3)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 128, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 470,114\n",
      "Trainable params: 470,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def swish_activation(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\", input_shape=(1,50,50)))\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(96, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(96, (3, 3), padding=\"valid\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"valid\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=swish_activation))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2 , activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_uuid": "671e43a7e0f1866e6dc751157f6d39aa96755d35",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam' , metrics=['accuracy'])\n",
    "steps_per_epoch = len(train_data) // batch_size\n",
    "validation_steps = len((test_x, test_y)) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_uuid": "9ca97682b7bedf82496cb760f10b8872ae6dd567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 15s - loss: 0.6923 - acc: 0.5042 - val_loss: 0.6888 - val_acc: 0.4936\n",
      "Epoch 2/20\n",
      " - 13s - loss: 0.6821 - acc: 0.5622 - val_loss: 0.6638 - val_acc: 0.6023\n",
      "Epoch 3/20\n",
      " - 13s - loss: 0.6474 - acc: 0.6266 - val_loss: 0.6047 - val_acc: 0.6751\n",
      "Epoch 4/20\n",
      " - 13s - loss: 0.6114 - acc: 0.6651 - val_loss: 0.5596 - val_acc: 0.7155\n",
      "Epoch 5/20\n",
      " - 13s - loss: 0.5688 - acc: 0.7070 - val_loss: 0.5109 - val_acc: 0.7480\n",
      "Epoch 6/20\n",
      " - 13s - loss: 0.5372 - acc: 0.7328 - val_loss: 0.4811 - val_acc: 0.7640\n",
      "Epoch 7/20\n",
      " - 13s - loss: 0.4782 - acc: 0.7704 - val_loss: 0.4526 - val_acc: 0.7904\n",
      "Epoch 8/20\n",
      " - 13s - loss: 0.4410 - acc: 0.7945 - val_loss: 0.4365 - val_acc: 0.7935\n",
      "Epoch 9/20\n",
      " - 13s - loss: 0.4108 - acc: 0.8122 - val_loss: 0.3799 - val_acc: 0.8251\n",
      "Epoch 10/20\n",
      " - 13s - loss: 0.3820 - acc: 0.8278 - val_loss: 0.3600 - val_acc: 0.8349\n",
      "Epoch 11/20\n",
      " - 13s - loss: 0.3651 - acc: 0.8346 - val_loss: 0.3503 - val_acc: 0.8390\n",
      "Epoch 12/20\n",
      " - 13s - loss: 0.3373 - acc: 0.8506 - val_loss: 0.3689 - val_acc: 0.8416\n",
      "Epoch 13/20\n",
      " - 13s - loss: 0.3224 - acc: 0.8562 - val_loss: 0.3345 - val_acc: 0.8487\n",
      "Epoch 14/20\n",
      " - 13s - loss: 0.3022 - acc: 0.8671 - val_loss: 0.3233 - val_acc: 0.8563\n",
      "Epoch 15/20\n",
      " - 13s - loss: 0.2942 - acc: 0.8717 - val_loss: 0.3119 - val_acc: 0.8646\n",
      "Epoch 16/20\n",
      " - 13s - loss: 0.2802 - acc: 0.8791 - val_loss: 0.3178 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 17/20\n",
      " - 13s - loss: 0.2411 - acc: 0.8970 - val_loss: 0.3121 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      " - 13s - loss: 0.2249 - acc: 0.9053 - val_loss: 0.3080 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 19/20\n",
      " - 13s - loss: 0.2189 - acc: 0.9072 - val_loss: 0.3132 - val_acc: 0.8711\n",
      "Epoch 20/20\n",
      " - 13s - loss: 0.2157 - acc: 0.9069 - val_loss: 0.3138 - val_acc: 0.8715\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(X, Y, batch_size=batch_size),\n",
    "                    steps_per_epoch=X.shape[0] // batch_size,\n",
    "                    callbacks=[lr_reduce],\n",
    "                    validation_data=(test_x, test_y),\n",
    "                    epochs = epochs, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaining a validation accuracy of 87.15 % with a self network architecture laid down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 gave around 88.3 % as validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f41c9194c281f9e2432b7ad32a9ca37f8f2d0291"
   },
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print('valid loss:', score[0])\n",
    "print('valid accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2dd16d81767f4493072e8bb13eeda453c1a119da",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Graphs are laid separately.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = making_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission_file.csv','w') as f:\n",
    "    f.write('id,label\\n')\n",
    "            \n",
    "with open('submission_file.csv','a') as f:\n",
    "    for data in tqdm(test_data):\n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(1,1,50,50)\n",
    "        model_out = model.predict([data])[0]\n",
    "        f.write('{},{}\\n'.format(img_num,model_out[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'submission_file' as the final submission file for the predictions in the test_data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
